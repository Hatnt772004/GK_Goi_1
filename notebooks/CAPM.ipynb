{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f50a962",
   "metadata": {},
   "source": [
    "## CAPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad692e2a",
   "metadata": {},
   "source": [
    "1. T√≠nh to√°n H·ªá s·ªë Beta v√† R·ªßi ro Phi h·ªá th·ªëng: s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p H·ªìi quy tuy·∫øn t√≠nh (OLS Regression) ƒë·ªÉ t√¨m m·ªëi quan h·ªá gi·ªØa l·ª£i su·∫•t c·ªßa t·ª´ng c·ªï phi·∫øu (bi·∫øn ph·ª• thu·ªôc y) v√† l·ª£i su·∫•t c·ªßa th·ªã tr∆∞·ªùng VN-INDEX (bi·∫øn ƒë·ªôc l·∫≠p x). T·ª´ ƒë√≥, tr√≠ch xu·∫•t ra h·ªá s·ªë beta (ƒëo l∆∞·ªùng r·ªßi ro h·ªá th·ªëng) v√† ph∆∞∆°ng sai c·ªßa ph·∫ßn d∆∞ (ƒëo l∆∞·ªùng r·ªßi ro phi h·ªá th·ªëng).\n",
    "\n",
    "2. D·ª±a v√†o h·ªá s·ªë Beta t√≠nh ƒë∆∞·ª£c, m√£ ngu·ªìn t·ª± ƒë·ªông x·∫øp lo·∫°i c√°c ng√¢n h√†ng v√†o 3 nh√≥m:\n",
    "- R·ªßi ro th·∫•p (beta<1)\n",
    "- R·ªßi ro trung b√¨nh (-1<beta<1.2)\n",
    "- R·ªßi co cao (beta>1.2)\n",
    "\n",
    "3. Xu·∫•t b√°o c√°o k·∫øt qu·∫£: M√£ ngu·ªìn l∆∞u tr·ªØ k·∫øt qu·∫£ v√†o 2 file CSV\n",
    "- capm_beta_results.csv: B·∫£ng ƒë·∫ßy ƒë·ªß c√°c ch·ªâ s·ªë th·ªëng k√™\n",
    "- beta_summary_table.csv: B·∫£ng r√∫t g·ªçn ch·ªâ g·ªìm Ticker v√† Beta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536c3e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ch·∫°y m√¥ h√¨nh CAPM (Ch 3.4)\n",
    "# PHI√äN B·∫¢N C·∫¨P NH·∫¨T: ƒê√£ ch·ªânh s·ª≠a ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c data_ohlcv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---\n",
    "DATA_FOLDER = 'data_ohlcv'\n",
    "INPUT_FILE = 'data_final.csv'\n",
    "INPUT_PATH = os.path.join(DATA_FOLDER, INPUT_FILE)\n",
    "\n",
    "# T√™n file k·∫øt qu·∫£ ƒë·∫ßu ra (s·∫Ω l∆∞u v√†o c√πng th∆∞ m·ª•c data)\n",
    "OUTPUT_FULL = os.path.join(DATA_FOLDER, 'capm_beta_results.csv')\n",
    "OUTPUT_SUMMARY = os.path.join(DATA_FOLDER, 'beta_summary_table.csv')\n",
    "\n",
    "def calculate_capm_beta(df, bank_tickers):\n",
    "    \"\"\"\n",
    "    T√≠nh h·ªá s·ªë Beta v√† R·ªßi ro Phi h·ªá th·ªëng (Var(epsilon_t)) cho c√°c m√£ \n",
    "    c·ªï phi·∫øu ng√¢n h√†ng b·∫±ng m√¥ h√¨nh CAPM (OLS).\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"B·∫ÆT ƒê·∫¶U T√çNH TO√ÅN H·ªÜ S·ªê BETA & R·ª¶I RO PHI H·ªÜ TH·ªêNG\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # L·ªçc ra CH·ªà c√°c c·ªï phi·∫øu ng√¢n h√†ng\n",
    "    df_stocks = df[df['ticker'].isin(bank_tickers)].copy()\n",
    "    \n",
    "    for ticker in bank_tickers:\n",
    "        print(f\"\\nüìä ƒêang x·ª≠ l√Ω: {ticker}\")\n",
    "        \n",
    "        # 1. L·ªçc d·ªØ li·ªáu cho c·ªï phi·∫øu hi·ªán t·∫°i\n",
    "        # C·∫ßn ƒë·∫£m b·∫£o c·ªôt VNI_log_return (ƒë√£ ƒë∆∞·ª£c merge t·ª´ b∆∞·ªõc tr∆∞·ªõc) t·ªìn t·∫°i\n",
    "        if 'VNI_log_return' not in df_stocks.columns:\n",
    "             print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y c·ªôt 'VNI_log_return'. Vui l√≤ng ch·∫°y l·∫°i b∆∞·ªõc Feature Engineering.\")\n",
    "             sys.exit()\n",
    "\n",
    "        stock_data = df_stocks[df_stocks['ticker'] == ticker][['log_return', 'VNI_log_return']].copy()\n",
    "        \n",
    "        # 2. Lo·∫°i b·ªè c√°c gi√° tr·ªã NaN\n",
    "        stock_data = stock_data.dropna(subset=['log_return', 'VNI_log_return'])\n",
    "        \n",
    "        # 3. Ki·ªÉm tra n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu\n",
    "        if len(stock_data) < 30: # C·∫ßn √≠t nh·∫•t 30 quan s√°t\n",
    "            print(f\"  ‚ö†Ô∏è  Kh√¥ng ƒë·ªß d·ªØ li·ªáu ({len(stock_data)} quan s√°t) sau khi lo·∫°i b·ªè NaN\")\n",
    "            results.append({\n",
    "                'Ticker': ticker, 'Beta': np.nan, 'Alpha': np.nan,\n",
    "                'R_squared': np.nan, \n",
    "                'Unsystematic_Risk_Var': np.nan,\n",
    "                'P_value': np.nan,\n",
    "                'Std_Error': np.nan, 'N_observations': len(stock_data)\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # 4. Chu·∫©n b·ªã d·ªØ li·ªáu cho h·ªìi quy\n",
    "        y = stock_data['log_return'].values\n",
    "        X = stock_data['VNI_log_return'].values \n",
    "        \n",
    "        # 5. Ch·∫°y OLS\n",
    "        X_with_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_with_const).fit()\n",
    "        \n",
    "        # L·∫•y k·∫øt qu·∫£\n",
    "        alpha = model.params[0]\n",
    "        beta = model.params[1]\n",
    "        r_squared = model.rsquared\n",
    "        p_value = model.pvalues[1]\n",
    "        std_error = model.bse[1]\n",
    "        \n",
    "        # T√≠nh R·ªßi ro Phi h·ªá th·ªëng (Var(epsilon))\n",
    "        unsystematic_risk_var = model.mse_resid\n",
    "        \n",
    "        # 6. L∆∞u k·∫øt qu·∫£\n",
    "        results.append({\n",
    "            'Ticker': ticker,\n",
    "            'Beta': beta,\n",
    "            'Alpha': alpha,\n",
    "            'R_squared': r_squared,\n",
    "            'Unsystematic_Risk_Var': unsystematic_risk_var,\n",
    "            'P_value': p_value,\n",
    "            'Std_Error': std_error,\n",
    "            'N_observations': len(stock_data)\n",
    "        })\n",
    "        \n",
    "        # In k·∫øt qu·∫£ chi ti·∫øt\n",
    "        print(f\"  ‚úì Beta: {beta:.4f}\")\n",
    "        print(f\"  ‚úì R¬≤: {r_squared:.4f}\")\n",
    "        print(f\"  ‚úì R·ªßi ro phi h·ªá th·ªëng (Var(Œµ)): {unsystematic_risk_var:.8f}\")\n",
    "        print(f\"  ‚úì S·ªë quan s√°t: {len(stock_data)}\")\n",
    "        \n",
    "    # T·∫°o DataFrame k·∫øt qu·∫£ v√† s·∫Øp x·∫øp\n",
    "    results_df = pd.DataFrame(results)\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values('Beta', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def print_summary_statistics(results_df):\n",
    "    \"\"\"\n",
    "    In th·ªëng k√™ t√≥m t·∫Øt v·ªÅ Beta\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TH·ªêNG K√ä T√ìM T·∫ÆT V·ªÄ H·ªÜ S·ªê BETA\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if results_df.empty or 'Beta' not in results_df.columns:\n",
    "        print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu k·∫øt qu·∫£.\")\n",
    "        return\n",
    "\n",
    "    valid_betas = results_df['Beta'].dropna()\n",
    "    \n",
    "    print(f\"\\nüìà S·ªë m√£ c√≥ Beta h·ª£p l·ªá: {len(valid_betas)}/{len(results_df)}\")\n",
    "    \n",
    "    if valid_betas.empty:\n",
    "        print(\"   ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu Beta h·ª£p l·ªá.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Beta trung b√¨nh: {valid_betas.mean():.4f}\")\n",
    "    print(f\"üìä Beta trung v·ªã: {valid_betas.median():.4f}\")\n",
    "    \n",
    "    max_idx = results_df['Beta'].idxmax()\n",
    "    min_idx = results_df['Beta'].idxmin()\n",
    "    print(f\"üìä Beta cao nh·∫•t: {valid_betas.max():.4f} ({results_df.loc[max_idx, 'Ticker']})\")\n",
    "    print(f\"üìä Beta th·∫•p nh·∫•t: {valid_betas.min():.4f} ({results_df.loc[min_idx, 'Ticker']})\")\n",
    "    print(f\"üìä ƒê·ªô l·ªách chu·∫©n: {valid_betas.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nüìã PH√ÇN LO·∫†I THEO M·ª®C ƒê·ªò R·ª¶I RO:\")\n",
    "    defensive = results_df[results_df['Beta'] < 1.0]\n",
    "    neutral = results_df[(results_df['Beta'] >= 1.0) & (results_df['Beta'] <= 1.2)]\n",
    "    aggressive = results_df[results_df['Beta'] > 1.2]\n",
    "    \n",
    "    print(f\"  üõ°Ô∏è  Defensive (Beta < 1.0): {len(defensive)} m√£\")\n",
    "    print(f\"  ‚öñÔ∏è  Neutral (1.0 ‚â§ Beta ‚â§ 1.2): {len(neutral)} m√£\")\n",
    "    print(f\"  üöÄ Aggressive (Beta > 1.2): {len(aggressive)} m√£\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CH∆Ø∆†NG TR√åNH CH√çNH\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"üìÇ ƒêang ƒë·ªçc file t·ª´: {INPUT_PATH}...\")\n",
    "    \n",
    "    # 1. Ki·ªÉm tra file t·ªìn t·∫°i\n",
    "    if not os.path.exists(INPUT_PATH):\n",
    "        print(f\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file '{INPUT_PATH}'.\")\n",
    "        print(\"   Vui l√≤ng ki·ªÉm tra l·∫°i t√™n th∆∞ m·ª•c ho·∫∑c ch·∫°y l·∫°i b∆∞·ªõc Feature Engineering.\")\n",
    "        sys.exit()\n",
    "\n",
    "    # 2. ƒê·ªçc d·ªØ li·ªáu\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_PATH)\n",
    "        print(f\"‚úì ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi ƒë·ªçc file: {e}\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # 3. Chuy·ªÉn ƒë·ªïi c·ªôt 'date'\n",
    "    try:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        print(\"‚úì ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt 'date' sang ƒë·ªãnh d·∫°ng datetime.\")\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªñI: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt 'date'. L·ªói: {e}\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # Danh s√°ch ng√¢n h√†ng c·∫ßn t√≠nh\n",
    "    bank_tickers = ['ACB', 'BID', 'CTG', 'HDB', 'LPB', 'MBB', \n",
    "                    'EIB', 'STB', 'TCB', 'TPB', 'VCB', 'VIB', \n",
    "                    'VPB', 'SHB'] # ƒê√£ b·ªè c√°c m√£ r√°c nh∆∞ MSB, NAB...\n",
    "    \n",
    "    # Ki·ªÉm tra xem m√£ c√≥ trong file kh√¥ng\n",
    "    available_tickers = df['ticker'].unique()\n",
    "    missing_tickers = [t for t in bank_tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        print(f\"\\n‚ö†Ô∏è  C·∫£nh b√°o: C√°c m√£ sau kh√¥ng c√≥ trong d·ªØ li·ªáu (c√≥ th·ªÉ ƒë√£ b·ªã l·ªçc): {missing_tickers}\")\n",
    "        bank_tickers = [t for t in bank_tickers if t in available_tickers]\n",
    "        \n",
    "    print(f\"\\nüìã S·∫Ω t√≠nh Beta cho {len(bank_tickers)} m√£ ng√¢n h√†ng\")\n",
    "    \n",
    "    # 4. T√≠nh Beta\n",
    "    results_df = calculate_capm_beta(df, bank_tickers)\n",
    "    \n",
    "    # 5. In th·ªëng k√™\n",
    "    print_summary_statistics(results_df)\n",
    "    \n",
    "    # 6. Hi·ªÉn th·ªã v√† L∆∞u k·∫øt qu·∫£\n",
    "    if not results_df.empty:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"B·∫¢NG K·∫æT QU·∫¢ CHI TI·∫æT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        cols_to_round = {\n",
    "            'Beta': 4, \n",
    "            'Alpha': 6, \n",
    "            'R_squared': 4, \n",
    "            'Unsystematic_Risk_Var': 8,\n",
    "            'P_value': 4, \n",
    "            'Std_Error': 6\n",
    "        }\n",
    "        \n",
    "        results_df_rounded = results_df.round(cols_to_round)\n",
    "        print(results_df_rounded.to_string(index=False))\n",
    "        \n",
    "        # L∆∞u file k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß\n",
    "        results_df.to_csv(OUTPUT_FULL, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ (ƒë·∫ßy ƒë·ªß) v√†o file: {OUTPUT_FULL}\")\n",
    "        \n",
    "        # L∆∞u file t√≥m t·∫Øt\n",
    "        simple_table = results_df[['Ticker', 'Beta']].copy()\n",
    "        simple_table.to_csv(OUTPUT_SUMMARY, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u b·∫£ng t√≥m t·∫Øt (Ticker, Beta) v√†o file: {OUTPUT_SUMMARY}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HO√ÄN TH√ÄNH!\")\n",
    "    print(\"=\" * 70)# Ch·∫°y m√¥ h√¨nh CAPM (Ch 3.4)\n",
    "# PHI√äN B·∫¢N C·∫¨P NH·∫¨T: ƒê√£ ch·ªânh s·ª≠a ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c data_ohlcv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---\n",
    "DATA_FOLDER = 'data_ohlcv'\n",
    "INPUT_FILE = 'data_final.csv'\n",
    "INPUT_PATH = os.path.join(DATA_FOLDER, INPUT_FILE)\n",
    "\n",
    "# T√™n file k·∫øt qu·∫£ ƒë·∫ßu ra (s·∫Ω l∆∞u v√†o c√πng th∆∞ m·ª•c data)\n",
    "OUTPUT_FULL = os.path.join(DATA_FOLDER, 'capm_beta_results.csv')\n",
    "OUTPUT_SUMMARY = os.path.join(DATA_FOLDER, 'beta_summary_table.csv')\n",
    "\n",
    "def calculate_capm_beta(df, bank_tickers):\n",
    "    \"\"\"\n",
    "    T√≠nh h·ªá s·ªë Beta v√† R·ªßi ro Phi h·ªá th·ªëng (Var(epsilon_t)) cho c√°c m√£ \n",
    "    c·ªï phi·∫øu ng√¢n h√†ng b·∫±ng m√¥ h√¨nh CAPM (OLS).\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"B·∫ÆT ƒê·∫¶U T√çNH TO√ÅN H·ªÜ S·ªê BETA & R·ª¶I RO PHI H·ªÜ TH·ªêNG\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # L·ªçc ra CH·ªà c√°c c·ªï phi·∫øu ng√¢n h√†ng\n",
    "    df_stocks = df[df['ticker'].isin(bank_tickers)].copy()\n",
    "    \n",
    "    for ticker in bank_tickers:\n",
    "        print(f\"\\nüìä ƒêang x·ª≠ l√Ω: {ticker}\")\n",
    "        \n",
    "        # 1. L·ªçc d·ªØ li·ªáu cho c·ªï phi·∫øu hi·ªán t·∫°i\n",
    "        # C·∫ßn ƒë·∫£m b·∫£o c·ªôt VNI_log_return (ƒë√£ ƒë∆∞·ª£c merge t·ª´ b∆∞·ªõc tr∆∞·ªõc) t·ªìn t·∫°i\n",
    "        if 'VNI_log_return' not in df_stocks.columns:\n",
    "             print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y c·ªôt 'VNI_log_return'. Vui l√≤ng ch·∫°y l·∫°i b∆∞·ªõc Feature Engineering.\")\n",
    "             sys.exit()\n",
    "\n",
    "        stock_data = df_stocks[df_stocks['ticker'] == ticker][['log_return', 'VNI_log_return']].copy()\n",
    "        \n",
    "        # 2. Lo·∫°i b·ªè c√°c gi√° tr·ªã NaN\n",
    "        stock_data = stock_data.dropna(subset=['log_return', 'VNI_log_return'])\n",
    "        \n",
    "        # 3. Ki·ªÉm tra n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu\n",
    "        if len(stock_data) < 30: # C·∫ßn √≠t nh·∫•t 30 quan s√°t\n",
    "            print(f\"  ‚ö†Ô∏è  Kh√¥ng ƒë·ªß d·ªØ li·ªáu ({len(stock_data)} quan s√°t) sau khi lo·∫°i b·ªè NaN\")\n",
    "            results.append({\n",
    "                'Ticker': ticker, 'Beta': np.nan, 'Alpha': np.nan,\n",
    "                'R_squared': np.nan, \n",
    "                'Unsystematic_Risk_Var': np.nan,\n",
    "                'P_value': np.nan,\n",
    "                'Std_Error': np.nan, 'N_observations': len(stock_data)\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # 4. Chu·∫©n b·ªã d·ªØ li·ªáu cho h·ªìi quy\n",
    "        y = stock_data['log_return'].values\n",
    "        X = stock_data['VNI_log_return'].values \n",
    "        \n",
    "        # 5. Ch·∫°y OLS\n",
    "        X_with_const = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X_with_const).fit()\n",
    "        \n",
    "        # L·∫•y k·∫øt qu·∫£\n",
    "        alpha = model.params[0]\n",
    "        beta = model.params[1]\n",
    "        r_squared = model.rsquared\n",
    "        p_value = model.pvalues[1]\n",
    "        std_error = model.bse[1]\n",
    "        \n",
    "        # T√≠nh R·ªßi ro Phi h·ªá th·ªëng (Var(epsilon))\n",
    "        unsystematic_risk_var = model.mse_resid\n",
    "        \n",
    "        # 6. L∆∞u k·∫øt qu·∫£\n",
    "        results.append({\n",
    "            'Ticker': ticker,\n",
    "            'Beta': beta,\n",
    "            'Alpha': alpha,\n",
    "            'R_squared': r_squared,\n",
    "            'Unsystematic_Risk_Var': unsystematic_risk_var,\n",
    "            'P_value': p_value,\n",
    "            'Std_Error': std_error,\n",
    "            'N_observations': len(stock_data)\n",
    "        })\n",
    "        \n",
    "        # In k·∫øt qu·∫£ chi ti·∫øt\n",
    "        print(f\"  ‚úì Beta: {beta:.4f}\")\n",
    "        print(f\"  ‚úì R¬≤: {r_squared:.4f}\")\n",
    "        print(f\"  ‚úì R·ªßi ro phi h·ªá th·ªëng (Var(Œµ)): {unsystematic_risk_var:.8f}\")\n",
    "        print(f\"  ‚úì S·ªë quan s√°t: {len(stock_data)}\")\n",
    "        \n",
    "    # T·∫°o DataFrame k·∫øt qu·∫£ v√† s·∫Øp x·∫øp\n",
    "    results_df = pd.DataFrame(results)\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values('Beta', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def print_summary_statistics(results_df):\n",
    "    \"\"\"\n",
    "    In th·ªëng k√™ t√≥m t·∫Øt v·ªÅ Beta\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TH·ªêNG K√ä T√ìM T·∫ÆT V·ªÄ H·ªÜ S·ªê BETA\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if results_df.empty or 'Beta' not in results_df.columns:\n",
    "        print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu k·∫øt qu·∫£.\")\n",
    "        return\n",
    "\n",
    "    valid_betas = results_df['Beta'].dropna()\n",
    "    \n",
    "    print(f\"\\nüìà S·ªë m√£ c√≥ Beta h·ª£p l·ªá: {len(valid_betas)}/{len(results_df)}\")\n",
    "    \n",
    "    if valid_betas.empty:\n",
    "        print(\"   ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu Beta h·ª£p l·ªá.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Beta trung b√¨nh: {valid_betas.mean():.4f}\")\n",
    "    print(f\"üìä Beta trung v·ªã: {valid_betas.median():.4f}\")\n",
    "    \n",
    "    max_idx = results_df['Beta'].idxmax()\n",
    "    min_idx = results_df['Beta'].idxmin()\n",
    "    print(f\"üìä Beta cao nh·∫•t: {valid_betas.max():.4f} ({results_df.loc[max_idx, 'Ticker']})\")\n",
    "    print(f\"üìä Beta th·∫•p nh·∫•t: {valid_betas.min():.4f} ({results_df.loc[min_idx, 'Ticker']})\")\n",
    "    print(f\"üìä ƒê·ªô l·ªách chu·∫©n: {valid_betas.std():.4f}\")\n",
    "    \n",
    "    print(\"\\nüìã PH√ÇN LO·∫†I THEO M·ª®C ƒê·ªò R·ª¶I RO:\")\n",
    "    defensive = results_df[results_df['Beta'] < 1.0]\n",
    "    neutral = results_df[(results_df['Beta'] >= 1.0) & (results_df['Beta'] <= 1.2)]\n",
    "    aggressive = results_df[results_df['Beta'] > 1.2]\n",
    "    \n",
    "    print(f\"  üõ°Ô∏è  Defensive (Beta < 1.0): {len(defensive)} m√£\")\n",
    "    print(f\"  ‚öñÔ∏è  Neutral (1.0 ‚â§ Beta ‚â§ 1.2): {len(neutral)} m√£\")\n",
    "    print(f\"  üöÄ Aggressive (Beta > 1.2): {len(aggressive)} m√£\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CH∆Ø∆†NG TR√åNH CH√çNH\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"üìÇ ƒêang ƒë·ªçc file t·ª´: {INPUT_PATH}...\")\n",
    "    \n",
    "    # 1. Ki·ªÉm tra file t·ªìn t·∫°i\n",
    "    if not os.path.exists(INPUT_PATH):\n",
    "        print(f\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file '{INPUT_PATH}'.\")\n",
    "        print(\"   Vui l√≤ng ki·ªÉm tra l·∫°i t√™n th∆∞ m·ª•c ho·∫∑c ch·∫°y l·∫°i b∆∞·ªõc Feature Engineering.\")\n",
    "        sys.exit()\n",
    "\n",
    "    # 2. ƒê·ªçc d·ªØ li·ªáu\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_PATH)\n",
    "        print(f\"‚úì ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi ƒë·ªçc file: {e}\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # 3. Chuy·ªÉn ƒë·ªïi c·ªôt 'date'\n",
    "    try:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        print(\"‚úì ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt 'date' sang ƒë·ªãnh d·∫°ng datetime.\")\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªñI: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt 'date'. L·ªói: {e}\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # Danh s√°ch ng√¢n h√†ng c·∫ßn t√≠nh\n",
    "    bank_tickers = ['ACB', 'BID', 'CTG', 'HDB', 'LPB', 'MBB', \n",
    "                    'EIB', 'STB', 'TCB', 'TPB', 'VCB', 'VIB', \n",
    "                    'VPB', 'SHB'] # ƒê√£ b·ªè c√°c m√£ r√°c nh∆∞ MSB, NAB...\n",
    "    \n",
    "    # Ki·ªÉm tra xem m√£ c√≥ trong file kh√¥ng\n",
    "    available_tickers = df['ticker'].unique()\n",
    "    missing_tickers = [t for t in bank_tickers if t not in available_tickers]\n",
    "    \n",
    "    if missing_tickers:\n",
    "        print(f\"\\n‚ö†Ô∏è  C·∫£nh b√°o: C√°c m√£ sau kh√¥ng c√≥ trong d·ªØ li·ªáu (c√≥ th·ªÉ ƒë√£ b·ªã l·ªçc): {missing_tickers}\")\n",
    "        bank_tickers = [t for t in bank_tickers if t in available_tickers]\n",
    "        \n",
    "    print(f\"\\nüìã S·∫Ω t√≠nh Beta cho {len(bank_tickers)} m√£ ng√¢n h√†ng\")\n",
    "    \n",
    "    # 4. T√≠nh Beta\n",
    "    results_df = calculate_capm_beta(df, bank_tickers)\n",
    "    \n",
    "    # 5. In th·ªëng k√™\n",
    "    print_summary_statistics(results_df)\n",
    "    \n",
    "    # 6. Hi·ªÉn th·ªã v√† L∆∞u k·∫øt qu·∫£\n",
    "    if not results_df.empty:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"B·∫¢NG K·∫æT QU·∫¢ CHI TI·∫æT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        cols_to_round = {\n",
    "            'Beta': 4, \n",
    "            'Alpha': 6, \n",
    "            'R_squared': 4, \n",
    "            'Unsystematic_Risk_Var': 8,\n",
    "            'P_value': 4, \n",
    "            'Std_Error': 6\n",
    "        }\n",
    "        \n",
    "        results_df_rounded = results_df.round(cols_to_round)\n",
    "        print(results_df_rounded.to_string(index=False))\n",
    "        \n",
    "        # L∆∞u file k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß\n",
    "        results_df.to_csv(OUTPUT_FULL, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ (ƒë·∫ßy ƒë·ªß) v√†o file: {OUTPUT_FULL}\")\n",
    "        \n",
    "        # L∆∞u file t√≥m t·∫Øt\n",
    "        simple_table = results_df[['Ticker', 'Beta']].copy()\n",
    "        simple_table.to_csv(OUTPUT_SUMMARY, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u b·∫£ng t√≥m t·∫Øt (Ticker, Beta) v√†o file: {OUTPUT_SUMMARY}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HO√ÄN TH√ÄNH!\")\n",
    "    print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
